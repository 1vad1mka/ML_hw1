# Результаты 

## Предобработка, EDA и визуализация
Я загрузил данные, посмотрел их размерность, проанализировал содержание данных. Далее была проведена проверка на наличие пропусков и явных дубликатов. В столцах
`mileage`, `engine`, `seats`, `max_power`, `torque` Были обнаружены пропуски. Явные дубликаты нашлись только в тестовом датасете. 

В качестве бонуса, я создал дашборд с помощью `ydata-profilling`.

После обнаружения пропусков, было принято решение заполнить их медианой. Но перед тем, как можно было заполнить пропуски, мне пришлось обработать признаки `mileage`, `engine`, `max_power`,
`torque` (убрать единицы измерения, привести к нужному типу). Столбцы были обработаны, после чего удалось успешно заполнить пропуски медианой.


После этого были изучены явные дубликаты, а также объекты с одинаковым признаковым описанием (без целевой переменной). Все найденные неявные дубликаты, а также объекты с  одинаковым признаковым описанием были удалены,
были оставлены первые встречающиеся. После этого были обновлены индексы без пропусков. Столбцы были приведены к более подходящим типам. А именно столбцы `engnine` и `seats` к `int`.


После этого были просмотрены основные статистики по количественным и текстовым/категориальным столбцам. Уже на этом этапе было замечено, что распределения тренировочных и тестовых данных похожи.


Для большей наглядности были построены графики:
- `pairplot` для тренировочной и тестовой выборок;
- `heatmap` для оценки корреляции Пирсона;
- зависимость цены от количества владельцев;
- зависимость между типом продавца и ценой
- зависимость между видом топлива и стоимостью автомобиля также очень важно.
- динамику цены (целевого признака) по годам
- зависимость признака `selling_price` от "бонусных" `признаков torque` и `max_torque_rpm`.


Из графиков можно предположить наличие связи между целевой переменной `selling_price` и признаками `year`, `engine`, `max_power`, `torque_nm`, `max_torque_nm`. С другими признаками связи менее очевидны.
Гипотезу о корреляции между некоторыми признаками выдвинуть можно, т.к. корреляция (Пирсона) отображает уровень линейной зависимости между признаками, а по графику можно проследить эту зависимость. Например, между mileage и engine , между max_power и engine , между max_power и torque_nm и т.д.
Во многих графиках видны выбросы. Если их удалить, то связь должна быть видна более явно. Было выяснено, что наименее скоррелированы между собой признаки `year` и `engine`, при этом  довольно сильная положительная линейная зависимость наблюдается между `engine` и `max_power`, между `engine` и `seats`, между `year` и `selling_price`, `engine`/`max_power` и `selling_price`
(если рассматривать также целевой признак), между `torque_nm` и `max_power`, между `torque_nm` и `engine` и т.п.


Видно, что медианная стоимость автомобилей, у которых владелец является первым, выше, чем у автомобилей, у которых владельцев было больше. То же самое касается и второго и третьего владельца. Машины на тест дравйв рассматривать не стоит, так как их всего лишь 4. В категории Trustmark Dealer не так много значений, но медианная стоимость выше всего, что логично, т.к.
Trustmark Dealer содержит проверенных дилеров. На втором месте по медианной стоимости расположены обчные дилеры. То есть индивидуальные продажи без посредничества дилеров имеют в среднем наименьшую стоимость. Автомобили на дизельном топливе в серднем имеют наибольшую стоимость. Потом идут автомобили на обычном бензине. 
Стоимость на автомобили в последние годы находится на пике. Приблизительно с 2003-2004 годов начинается стабильный рост, который прервался только около 
г., после чего началось падение. Видно, что есть неплохая зависимость между `torque_nm` и `selling_price`. То есть метрика должна улучшиться после добавления этого признака.



## Обучение моделей

### Linear Regression без scaler'а и со scaler'ом
Для первой модели были использованы только вещественные признаки, так как чем больше признаковое пространство — чем сложнее модель. а чем модель проще — тем лучше для скорости работы и интерпретации признаков.
Предварительно были выделены матрица признаков, а также вектор с целевой переменной как для тренировочной, так и для тестовой выборок.

Коэффициент детерминации достаточно низок (около $0,6$). Это достаточно плохой результат. Также корень из MSE достаточно высокий, т.е. модель ошибается в среднем более чем на $470000$ единиц (RMSE). В целом модель недообучена, т.е. смещение слишком велико.

После применения стандартизации метрики никак не изменились, но это позволило лучше интерпретировать признаки (Чем больше веса по модулю, тем важнее признак). Выяснилось, что самыми важными признаками являются `max_power`, `year`, `max_torque_rpm` и т.д. 


### Lasso 
В качестве попытки улучшить результат было предпринято использовать регуляризацию `L1` - lasso регрессию. Её важное свойство - зануления незначимых коэффициентов.
В результате обуения модели на тренировочном наборе данных с нормализованными признаками  метрики почти не изменились, качество не улучшилось. При этом L1-регуляризация с параметрами по умолчанию не занулила никаких весов. 
Скорее всего, это произошло потому, что коэффициент регуляризации был слишком маленьким. Возможно, нужно увеличить значение alpha. Если сильно увеличить коэффициент alpha , то коэффициетны начнут зануляться (проверял).
Метрика `r2` по-прежнему около $0.6$ , rmse около $480000$. Наиболее важными признаками по-прежнему являются `max_power`, `year` и `max_torque_rpm`.


### Подбор параметров для Lasso
Далее было необходимо было подобрать гиперпараметры для `Lasso`-регрессии с помощью `GridSearchCV`. Гиперпараметры подбирались перебором по сетке (c 10-ю фолдами). Гиперпараметры подбирались в диапазоне от $1$ до $100$. 
В итоге грид-сёрчу пришлось обучать $10 \cdot 100 = 1000$ моделей. У лучшей из перебранных моделе коэффициент регуляризации равен 100. Веса не занулились. 

В итоге результаты ухудшились. Лучшая метрика $R^2$ на кросс-валидации равна $0.575$ , показатели на тесте около $0.53$. В итоге результаты ухудшились. Важность признаков осталось приблизительно такой же.


### Подбор гиперпараметров для ElasticNet
После подбора гиперпараметров для Lasso нужно подобрать параметры для `ElasticNet`. Для этого с помощью `GridSearchCV` перебором по сетке (c 10-ю фолдами) перебирались параметры `alpha` и `l1_ratio`. 
Гиперпараметры `alpha` перебирались в диапазоне $1$ до $100$ , а `l1_ratio` в диапазоне от $0.1$ до $0.7$.

В итоге грид-сёрчу пришлось обучать: $10 \cdot 100 \cdot 7 = 7000$ моделей. Лучшей модели соответствуют гиперпараметры `alpha=1`, `l1_ratio=0.7`.
Лушчая метрика $R^2$ на кросс-валидации - 0.5746168147535904. В целом качество модели пр-прежнему низкая. 


### Добавление категориальных признаков
Попробуем для улучшения модели дать ей больше признаков. Добавим категориальные фичи. При этом дополнительно прежобработаем признак `name`. В этом признаке более $1900$ категорий. 

Чтобы обработать этот признак, можно выделить из него:
- фирму машины;
- модель машины.


Модель машины выделить достаточно сложно, и он создает много уникальных значений. Поэтому мы выделим из него фирму машины (BMW, Audi и т.п.) Таким образом, количество категорий сократится до $30$.


После этого я создал `ColumnTransformer` , в который добавил стандартизацию для числовых признаков и **OneHot-кодирование** для категориальных/текстовых и признака `seats`. При этом во избежание мультиколлинеарности следует избавиться от одного из полученных столбцов при кодировании каждого признака методом OneHot.


### Ridge, подбор гиперпараметров
После этого я попробовал обучить `Ridge`-регрессию и подобрать её гиперпараметры на данных с категориальными признаками.
Нужно подобрать гиперпараметр `alpha` для гребневой (ridge) регрессии с помощью класса `GridSearchCV`, кроссвалидируясь по 10-ти фолдам.
Гиперпараметр `alpha` подбиралися в диапазоне от $200$ до $500$ с шагом $5$.

В итоге лучшая метрика на кросс-валидации составила $0.653$  , на тесте $0.625$. Видно улучшение в качестве модели. Однако сама по себе метрика все еще не велика.


## Бизнес-задача 
Далее нужно было написать кастомную метрику, хорошо интерпретируемую бизнесом. Среди всех предсказанных цен на авто нужно было посчитать долю прогнозов, отличающихся от реальных цен на эти авто не более чем на 10% (в одну или другую сторону).

Нужно было:
- реализовать метрику business_metric;
- посчитать метрику для всех обученных моделей и определеить, какаю лучше всего решает задачу бизнеса.


После расчета метрик для каждой модели:
- `linear_reg` - $0.244$
- `lasso` - $0.243$
- `elastic` - $0.271$
- `ridge` - $0.204$


На данный момент лучше всего задачу решает `elastic`-регрессия (а также `lasso`), но в целом модели недообучены и имеют низкую предсказательную способность.



## Сервис на FastAPI
После обучения и подбора модели нужно было реализовать для неё REST API с помощью фреймворка FastAPI. Для этого я вначале:
1. создал pipeline с автоматической предобработкой количественных и категориальных признаков и обучением модели;
2. создал отдельную функцию для первичной предобработки данных, которая приводит данные к нужному типу;
3. написал FastAPI приложение, которое имеет 2 endpoint'а: `/predict_item` (принимает json, возвращает `float`) и `/predict_items` (принимает `csv` и возвращает `csv`).
4. протестировал приложение и приложил соответствующие скриншоты.


Пайплайн для количественных данных заполняет пропуски медианой, и использует StandardScaler для нормализации данных. Пайплайн для категориальных данных заполняет пропуски модой и кодирует значение с помощью OneHot кодирования, отбрасывая при этом первое значение (для избежания мультиколлинеарности) и игнорируя неизвестные категории. В качестве модели я выбрал `elastic`-регрессию, обученную на всех признаках т.к. она показала наибольшую бизнес метрику $0.271$ , т.е. наилучшим образом решает задачи бизнеса. Весь пайплайн был сериализован с помощью библиотеки `pickle` и был назван `elastic_regressor.pkl`. Последним шагом работы в ноутбуке стало создание тестовых сэмплов для проверки API. В качестве тестирования endpoint'а `/predict_item` я выбрал первый вектор признаков:
![alt text](<Снимок экрана 2024-12-02 112745-1.png>)

Для тестирования ручки `/predict_items` было взято первые 10 объектов, которые были записаны в `test_service.csv`.
![alt text](<Снимок экрана 2024-12-02 112809-1.png>)


Для начала проверялась работа endpoint'а `/predict_item`. Вот результаты:
![alt text](<Снимок экрана 2024-12-02 114922.png>)

Видно, что код ответа $200$ , т.е. сервер успешно обработал запрос и вернул ответ в формате `float`, который равен $434385.884319911$. 

После этого я проверил работу endpoint'а `/predict_items`. Вот результаты:
![alt text](<Снимок экрана 2024-12-02 114955.png>)

Я передал файл `test_service.csv` и получил возможность скачать файл `response.csv`. После этого я прочитал его и вывел в ноутбуке:
![alt text](<Снимок экрана 2024-12-02 115127.png>)

Видно, что файл имеет необходимую структуру: используемые признаки (уже обработанные) и предсказание цены автомобиля. 

Таким образом, сервис работает и REST API было успешно создано.
