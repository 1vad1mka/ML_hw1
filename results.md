# Результаты 

## Предобработка, EDA и визуализация
Я загрузил данные, посмотрел их размерность, проанализировал содержание данных. Далее была проведена проверка на наличие пропусков и явных дубликатов. В столбцах
`mileage`, `engine`, `seats`, `max_power`, `torque` Были обнаружены пропуски. В целом пропусков немного: В тренировочных данных от 196 до 203, в тестовых по 19 в каждом из упомянутых столбцов. Явные дубликаты нашлись как в тренировочных (985), так и в тестовых (62) данных.

В качестве бонуса, я создал дашборд с помощью `ydata-profilling`, сохранил его в notebook'е. В нем представлен подробный однофакторный/многофакторный анализ основных признаков.

После обнаружения пропусков, было принято решение заполнить их медианой. Но перед тем, как можно было заполнить пропуски, мне пришлось обработать признаки `mileage`, `engine`, `max_power`, `torque` (убрать единицы измерения, привести к нужному типу). Обработка столбца `torque` - это моя инициатива (такого задания не было в дз).  Столбцы были обработаны, после чего удалось успешно заполнить пропуски медианой. Для каждого столбца медиана расчитывалась на тренировочных данных и затем заполнялась циклом `for` как в тренировочных, так и в тестовых.


После этого были изучены явные дубликаты, а также объекты с одинаковым признаковым описанием (без целевой переменной). Все найденные неявные дубликаты, а также объекты с одинаковым признаковым описанием были удалены. При этом из объектов с одинаковым признаковым описанием были оставлены первые встречающиеся. После этого были обновлены индексы без пропусков от нуля до конца. Столбцы были приведены к более подходящим типам. А именно столбцы `engnine` и `seats` к типу `int`.

Теперь, когда все столбцы были предобработаны, появилась возможность изучить основные статистики по количественным и текстовым/категориальным столбцам. Уже на этом этапе было замечено, что распределения тренировочных и тестовых данных похожи. Далее это потвердится на графическом анализе.


Для большей наглядности были построены графики:
- `pairplot` для тренировочной и тестовой выборок;
- `heatmap` для оценки корреляции Пирсона;
- зависимость цены от количества владельцев;
- зависимость между типом продавца и ценой
- зависимость между видом топлива и стоимостью автомобиля также очень важно.
- динамику цены (целевого признака) по годам
- зависимость признака `selling_price` от "бонусных" `признаков torque` и `max_torque_rpm`.


Из графиков можно предположить наличие связи между целевой переменной `selling_price` и признаками `year`, `engine`, `max_power`, `torque_nm`, `max_torque_nm`. С другими признаками связи менее очевидны. Гипотезу о корреляции между некоторыми признаками выдвинуть можно, т.к. корреляция (Пирсона) отображает уровень линейной зависимости между признаками, а по графику можно проследить эту зависимость. Например, между mileage и engine , между max_power и engine , между max_power и torque_nm и т.д.
Во многих графиках видны выбросы. Если их удалить, то связь должна быть видна более явно. Было выяснено, что наименее скоррелированы между собой признаки `year` и `engine` (0.0028), при этом  довольно сильная положительная линейная зависимость наблюдается между `engine` и `max_power`, между `engine` и `seats`, между `year` и `selling_price`, `engine`/`max_power` и `selling_price` (если рассматривать также целевой признак), между `torque_nm` и `max_power`, между `torque_nm` и `engine` и т.п.


Видно, что медианная стоимость автомобилей, у которых владелец является первым, выше, чем у автомобилей, у которых владельцев было больше. То же самое касается и второго и третьего владельца. Машины на тест дравйв рассматривать не стоит, так как их всего лишь 4. 

Если анализировать не только количество владельцев, но и тип продавца, то можно заметить, что в категории `Trustmark Dealer` не так много значений, но медианная стоимость выше всего, что логично, т.к. `Trustmark Dealer` содержит проверенных дилеров. На втором месте по медианной стоимости расположены обчные дилеры. То есть индивидуальные продажи без посредничества дилеров имеют в среднем наименьшую стоимость. 

В зависимости от безнина, автомобили на дизельном топливе в серднем имеют наибольшую стоимость. Потом идут автомобили на обычном бензине и на других видах топлива. Таким образом, информация о типе топлива должна быть достаточно полезным признаком.  

Стоимость на автомобили в последние годы находится на пике. Приблизительно с 2003-2004 годов начинается стабильный рост, который прервался только около 
г., после чего началось падение. Значит, что год продажи обязательно нужно использовать в модели.

Видно, что есть неплохая зависимость между `torque_nm` и `selling_price`. То есть метрика должна улучшиться после добавления этого признака. В целом, это логично, ведь автомобили с более мощным двигателем/тягой должны, соответственно, стоить больше.



## Обучение моделей

### Linear Regression без scaler'а и со scaler'ом
Для первой модели были использованы только вещественные признаки, так как чем больше признаковое пространство — чем сложнее модель. а чем модель проще — тем лучше для скорости работы и интерпретации признаков. Предварительно были выделены матрица признаков, а также вектор с целевой переменной как для тренировочной, так и для тестовой выборок. Дополнительно я написал функцию для расчета основных метрик на тренировочных и тестовых данных.

Коэффициент детерминации достаточно низок (около $0,6$). Это достаточно плохой результат. Также корень из MSE достаточно высокий, т.е. модель ошибается в среднем более чем на $470000$ единиц (RMSE). В целом модель недообучена, т.е. смещение слишком велико.

После применения стандартизации метрики никак не изменились, но это позволило лучше интерпретировать признаки (Чем больше веса по модулю, тем важнее признак). Выяснилось, что самыми важными признаками являются `max_power`, `year`, `max_torque_rpm` и т.д. Это во многом подтвержает результаты корреляционного и графического анализов.


### Lasso 
В качестве попытки улучшить результат было предпринято использовать регуляризацию `L1` - lasso регрессию. Её важное свойство - зануления незначимых коэффициентов.
В результате обуения модели на тренировочном наборе данных с нормализованными признаками  метрики почти не изменились, качество не улучшилось. При этом L1-регуляризация с параметрами по умолчанию не занулила никаких весов. Скорее всего, это произошло потому, что коэффициент регуляризации был слишком маленьким. Возможно, нужно увеличить значение alpha. Если сильно увеличить коэффициент alpha , то коэффициетны начнут зануляться (проверял). Метрика `r2` по-прежнему около $0.6$ , rmse около $480000$. Наиболее важными признаками по-прежнему являются `max_power`, `year` и `max_torque_rpm`.


### Подбор параметров для Lasso
Далее было необходимо было подобрать гиперпараметры для `Lasso`-регрессии с помощью `GridSearchCV`. Гиперпараметры подбирались перебором по сетке (c 10-ю фолдами). Гиперпараметры подбирались в диапазоне от $1$ до $100$. В итоге грид-сёрчу пришлось обучать $10 \cdot 100 = 1000$ моделей. У лучшей из перебранных моделе коэффициент регуляризации равен 100. Веса не занулились. В итоге результаты ухудшились. Лучшая метрика $R^2$ на кросс-валидации равна $0.575$ , показатели на тесте около $0.53$. В итоге результаты ухудшились. Важность признаков осталось приблизительно такой же.


### Подбор гиперпараметров для ElasticNet
После подбора гиперпараметров для Lasso нужно подобрать параметры для `ElasticNet`. Для этого с помощью `GridSearchCV` перебором по сетке (c 10-ю фолдами) перебирались параметры `alpha` и `l1_ratio`. Гиперпараметры `alpha` перебирались в диапазоне $1$ до $100$ , а `l1_ratio` в диапазоне от $0.1$ до $0.7$. В итоге грид-сёрчу пришлось обучать: $10 \cdot 100 \cdot 7 = 7000$ моделей. Лучшей модели соответствуют гиперпараметры `alpha=1`, `l1_ratio=0.7`. Лушчая метрика $R^2$ на кросс-валидации - 0.5746168147535904. В целом качество модели пр-прежнему низкое. 


### Добавление категориальных признаков
В качестве улучшения модели была сделана попытка увеличить пространство признаков через добавление категориальных признаков. При этом дополнительно был предобработан признак `name`. В этом признаке было более $1900$ категорий. 

Чтобы обработать этот признак, можно выделить из него:
- фирму машины;
- модель машины.


Модель машины выделить достаточно сложно, и он создает много уникальных значений. Поэтому мы выделим из него фирму машины (BMW, Audi и т.п.) Таким образом, количество категорий сократится до $30$.


После этого я создал `ColumnTransformer` , в который добавил стандартизацию для числовых признаков и **OneHot-кодирование** для категориальных/текстовых и признака `seats`. При этом во избежание мультиколлинеарности я избавился от одного из полученных столбцов при кодировании каждого признака методом OneHot.

В итоге, можно зайти вперед и сказать, что это дало видимый прирост в качестве.


### Ridge, подбор гиперпараметров
После этого я попробовал обучить `Ridge`-регрессию и подобрать её гиперпараметры на данных с категориальными признаками.
Нужно подобрать гиперпараметр `alpha` для гребневой (ridge) регрессии с помощью класса `GridSearchCV`, кроссвалидируясь по 10-ти фолдам.
Гиперпараметр `alpha` подбиралися в диапазоне от $200$ до $500$ с шагом $5$.

В итоге лучшая метрика на кросс-валидации составила $0.653$  , на тесте $0.625$. Видно улучшение в качестве модели. Однако сама по себе метрика все еще не велика.


## Бизнес-задача 
Далее нужно было написать кастомную метрику, хорошо интерпретируемую бизнесом. Среди всех предсказанных цен на авто нужно было посчитать долю прогнозов, отличающихся от реальных цен на эти авто не более чем на 10% (в одну или другую сторону).

Нужно было:
- реализовать метрику business_metric;
- посчитать метрику для всех обученных моделей и определеить, какаю лучше всего решает задачу бизнеса.


После расчета метрик для каждой модели:
- `linear_reg` - $0.244$
- `lasso` - $0.243$
- `elastic` - $0.271$
- `ridge` - $0.204$


На данный момент лучше всего задачу бизнеса решает `elastic`-регрессия (а также `lasso`), но в целом модели недообучены и имеют низкую предсказательную способность.


## Итоги
На данном этапе я провел DS-часть работы. Модель пока что является недообученой, имеет большое смещение. Наибольший буст модели дало добавление категориальных фичей. Но в целом не удалось поднять метрику на приемлемый уровень (хотя бы $R^2 = 0.7$).






